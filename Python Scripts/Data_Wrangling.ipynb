{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Project: Fantasy Premier League (FPL) Points Predictor\n",
    "## Data Rules Everything Around Me (DREAM) TEAM - Fall 2024 - CME 538\n",
    "## Feras Abdulla - Maha Fakhroo - Syed Shahid Hossaini - Eric Guan\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Data Wrangling\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### Objective:\n",
    "The purpose of this Python script is to collect, align, and merge data from different sources and covering different football seasons into a single `'master'` file. This new `'master'` file will be used for data cleaning/processing, exploratory data analysis (EDA), and creating visualizations (see EDA_Visuals.ipynb), and a filtered version will be split into training and testing subsets to create and evaluate an ML points predictor model (see ML_Points_Predictor.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources:\n",
    "We have relied on 3 main sources of data:\n",
    "\n",
    "1) `Vaastav's 'Fantasy-Premier-League' Github Repository`: One of the most comprehensive, publicly available FPL repositories. Contains `downloadable csv files` that track summary statistics for the whole season, fixture information, team data, gameweek-specific metrics, and prior historical player data. The information has been collated by season, by player, and by gameweek. We will utilize the `'merged_gw'` files available on this repository, which contain gameweek-by-gameweeek stats for all players in a single file for a single season. \n",
    "\n",
    "`Reference`: \n",
    "Anand, V. (2022). FPL historical dataset. Retrieved November 2024, from https://github.com/vaastav/Fantasy-Premier-League/\n",
    "\n",
    "2) `Official FPL API`: Contains overview statistics and detailed player data for the current season (2024-2025). The overview statistics can be accessed via the Official FPL website's `bootstrap-static` API, while the detailed player info can be obtained using that same API's element summary endpoint. \n",
    "\n",
    "`Reference`:\n",
    "Fantasy Premier League. (n.d.). FPL API. Retrieved November 2024, from https://fantasy.premierleague.com/api/ \n",
    "\n",
    "3) `Understat API`: Provides access to advanced football statistics and metrics for teams, players, and matches. It can be used to retrieve match details, player statistics, team performance, and seasonal summaries. This API will be used to extract expected goals (xG), expected assists (xA), and expected goal involvements (xGI) for each player in earlier seasons, since the `'merged_gw'` files from the `Vaastav` repository do not provide that information prior to the 2022-2023 season.\n",
    "\n",
    "`Reference`:\n",
    "Understat. (n.d.). Understat API. Retrieved November 2024, from https://understat.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "Imports essential Python libraries for data wrangling. These will be used to extract data from API endpoints, wrangle information across files, and align and publish a filtered data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import time\n",
    "import os\n",
    "import asyncio\n",
    "from understat import Understat\n",
    "import aiohttp\n",
    "from datetime import timedelta\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data from the Official FPL API\n",
    "\n",
    "First, we will obtain data from the FPL API at the bootstrap-static endpoint and organize it into structured dataframes. We will extract the following key categories: \n",
    "1) Player details (elements)\n",
    "2) Positions (element_types) \n",
    "3) Teams (teams) \n",
    "4) Gameweeks (events)\n",
    "\n",
    "Columns in the elements DataFrame are renamed for better clarity and merged with team and position DataFrames to add team names and player positions. After cleaning and merging redundant columns, the final DataFrame (elements_final) provides detailed player information, including team and position details. The cleaned player data is also saved as a CSV file (fpl_elements.csv) for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chance_of_playing_next_round  chance_of_playing_this_round    code  \\\n",
      "0                           0.0                           0.0  438098   \n",
      "1                         100.0                         100.0  205651   \n",
      "2                         100.0                         100.0  226597   \n",
      "3                         100.0                         100.0  219847   \n",
      "4                           0.0                           0.0  463748   \n",
      "\n",
      "   cost_change_event  cost_change_event_fall  cost_change_start  \\\n",
      "0                  0                       0                 -1   \n",
      "1                  0                       0                 -2   \n",
      "2                  0                       0                  1   \n",
      "3                  0                       0                  0   \n",
      "4                  0                       0                  0   \n",
      "\n",
      "   cost_change_start_fall  dreamteam_count  Position ID ep_next  ...  \\\n",
      "0                       1                0            3     0.0  ...   \n",
      "1                       2                0            4     1.8  ...   \n",
      "2                      -1                1            2     3.8  ...   \n",
      "3                       0                1            4     2.0  ...   \n",
      "4                       0                0            1     0.0  ...   \n",
      "\n",
      "  form_rank_type  points_per_game_rank points_per_game_rank_type  \\\n",
      "0            295                   665                       303   \n",
      "1             37                   444                        47   \n",
      "2             26                    42                         4   \n",
      "3             34                    45                        15   \n",
      "4             47                   497                        54   \n",
      "\n",
      "  selected_rank  selected_rank_type  starts_per_90 clean_sheets_per_90 id_y  \\\n",
      "0           632                 280           0.00                0.00    1   \n",
      "1           213                  37           0.85                0.43    1   \n",
      "2            11                   3           1.04                0.35    1   \n",
      "3            39                   9           1.00                0.27    1   \n",
      "4           551                  68           0.00                0.00    1   \n",
      "\n",
      "   Team Name Position Name  \n",
      "0    Arsenal    Midfielder  \n",
      "1    Arsenal       Forward  \n",
      "2    Arsenal      Defender  \n",
      "3    Arsenal       Forward  \n",
      "4    Arsenal    Goalkeeper  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fetch the data from the FPL API\n",
    "url = \"https://fantasy.premierleague.com/api/bootstrap-static/\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Organize the main data categories into DataFrames\n",
    "elements_df = pd.DataFrame(data['elements'])  # Player statistics and details\n",
    "element_types_df = pd.DataFrame(data['element_types'])  # Player positions\n",
    "teams_df = pd.DataFrame(data['teams'])  # Team information\n",
    "events_df = pd.DataFrame(data['events'])  # Gameweeks\n",
    "game_settings_df = pd.DataFrame([data['game_settings']])  # Game settings\n",
    "phases_df = pd.DataFrame(data['phases'])  # Season phases\n",
    "\n",
    "# Save file in 'Official FPL API Files' Folder\n",
    "elements_df.to_csv(\"../Official FPL API Files/fpl_elements.csv\", index=False)\n",
    "\n",
    "# Renaming columns in elements_df to more descriptive names for convenience\n",
    "elements_df = elements_df.rename(columns={\n",
    "    'team': 'Team ID',\n",
    "    'element_type': 'Position ID',\n",
    "    'total_points': 'Total Points',\n",
    "    'now_cost': 'Current Price',\n",
    "    'selected_by_percent': 'Selected By (%)'\n",
    "})\n",
    "\n",
    "# Merge elements_df with teams_df to get team names for players\n",
    "elements_with_teams = elements_df.merge(teams_df[['id', 'name']], how='left', left_on='Team ID', right_on='id')\n",
    "elements_with_teams.rename(columns={'name': 'Team Name'}, inplace=True)\n",
    "\n",
    "# Drop redundant 'id' column only if it exists\n",
    "if 'id' in elements_with_teams.columns:\n",
    "    elements_with_teams.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Merge elements_with_teams with element_types_df to get position names for players\n",
    "elements_final = elements_with_teams.merge(element_types_df[['id', 'singular_name']], how='left', left_on='Position ID', right_on='id')\n",
    "elements_final.rename(columns={'singular_name': 'Position Name'}, inplace=True)\n",
    "\n",
    "# Drop redundant 'id' column from element_types_df merge only if it exists\n",
    "if 'id' in elements_final.columns:\n",
    "    elements_final.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Display the final DataFrame structure\n",
    "print(elements_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's proceed with getting detailed player data rather than just seasonal overview statistics. Here, we intend to build a comprehensive dataset of player performance from the official FPL API across gameweeks focusing on the ongoing, 2024-2025 season.\n",
    "\n",
    "The columns player IDs, first names, and last names are extracted from fpl_elements.csv to facilitate merging with gameweek data later. The element-summary endpoint of the FPL API will be engaged to store data for every player's performance across all gameweeks using each player's unique ID. For each gameweek entry, the code adds the player's ID, first name, and last name to the record before appending it to the list. After collecting data for all players, the list is converted into a DataFrame (gameweek_df). The first few rows of the processed DataFrame are presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   element  fixture  opponent_team  total_points  was_home  \\\n",
      "0        1        2             20             0      True   \n",
      "1        1       11              2             0     False   \n",
      "2        1       21              5             0      True   \n",
      "3        1       39             18             0     False   \n",
      "4        1       47             13             0     False   \n",
      "\n",
      "           kickoff_time  Goals_for_Home_Team  Goals_for_Away_Team  Gameweek  \\\n",
      "0  2024-08-17T14:00:00Z                  2.0                  0.0         1   \n",
      "1  2024-08-24T16:30:00Z                  0.0                  2.0         2   \n",
      "2  2024-08-31T11:30:00Z                  1.0                  1.0         3   \n",
      "3  2024-09-15T13:00:00Z                  0.0                  1.0         4   \n",
      "4  2024-09-22T15:30:00Z                  2.0                  2.0         5   \n",
      "\n",
      "   minutes  ...  expected_goal_involvements  expected_goals_conceded  \\\n",
      "0        0  ...                        0.00                     0.00   \n",
      "1        0  ...                        0.00                     0.00   \n",
      "2        0  ...                        0.00                     0.00   \n",
      "3        0  ...                        0.00                     0.00   \n",
      "4        0  ...                        0.00                     0.00   \n",
      "\n",
      "   Market_Price  transfers_balance  selected  transfers_in  transfers_out  \\\n",
      "0            55                  0      2923             0              0   \n",
      "1            55               -790      2321            84            874   \n",
      "2            54               -279      2397           355            634   \n",
      "3            54               -747      1650             0            747   \n",
      "4            54               -174      1494             0            174   \n",
      "\n",
      "   player_id  first_name        last_name  \n",
      "0          1       Fábio  Ferreira Vieira  \n",
      "1          1       Fábio  Ferreira Vieira  \n",
      "2          1       Fábio  Ferreira Vieira  \n",
      "3          1       Fábio  Ferreira Vieira  \n",
      "4          1       Fábio  Ferreira Vieira  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the elements data to get player names and IDs\n",
    "elements_df = pd.read_csv(\"../Official FPL API Files/fpl_elements.csv\")\n",
    "\n",
    "# Select only the necessary columns for merging later\n",
    "elements_df = elements_df[['id', 'first_name', 'second_name']]\n",
    "\n",
    "# Initialize an empty list to collect data for each player per gameweek\n",
    "all_gameweek_data = []\n",
    "\n",
    "# Loop through each player's ID in elements_df\n",
    "for _, row in elements_df.iterrows():\n",
    "    player_id = row['id']\n",
    "    first_name = row['first_name']\n",
    "    last_name = row['second_name']\n",
    "    \n",
    "    # Fetch gameweek data for each player\n",
    "    url = f\"https://fantasy.premierleague.com/api/element-summary/{player_id}/\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        player_data = response.json()\n",
    "        \n",
    "        # Extract each gameweek's data and add it to our list\n",
    "        for gameweek in player_data['history']:\n",
    "            # Add player ID, first name, and last name to each gameweek record\n",
    "            gameweek['player_id'] = player_id\n",
    "            gameweek['first_name'] = first_name\n",
    "            gameweek['last_name'] = last_name\n",
    "            all_gameweek_data.append(gameweek)\n",
    "    \n",
    "    # Optional: Sleep to avoid rate limiting\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Convert the collected gameweek data into a DataFrame\n",
    "gameweek_df = pd.DataFrame(all_gameweek_data)\n",
    "\n",
    "# Rename columns for clarity where applicable\n",
    "column_renames = {\n",
    "    'round': 'Gameweek',\n",
    "    'team_h_score': 'Goals_for_Home_Team',\n",
    "    'team_a_score': 'Goals_for_Away_Team',\n",
    "    'bonus': 'Bonus_Points',\n",
    "    'value': 'Market_Price',\n",
    "    'ict_index': 'Influence_Creativity_Threat_Index',\n",
    "    'influence': 'Influence_Score',\n",
    "    'creativity': 'Creativity Score',\n",
    "    'threat': 'Threat Score',\n",
    "}\n",
    "\n",
    "gameweek_df.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(gameweek_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can convert all dataframe to CSV files and save them in the Official API Files folder:\n",
    "\n",
    "`'fpl_element_types.csv'`: A CSV file containing details about player positions, such as their IDs and names (e.g., Goalkeeper, Forward).\n",
    "\n",
    "`'fpl_teams.csv'`: A CSV file with team information, including team IDs, names, and other attributes like strength and performance.\n",
    "\n",
    "`'fpl_events.csv'`: A CSV file with gameweek information, including details like deadlines, fixture results, and gameweek IDs.\n",
    "\n",
    "`'fpl_game_settings.csv'`: A CSV file with overall game settings, such as scoring rules, transfer rules, and other configuration details for the season.\n",
    "\n",
    "`'fpl_phases.csv'`: A CSV file containing data about the phases of the season (e.g., first half, second half) and their respective start and end dates.\n",
    "\n",
    "`'FPL API 2024-2025 Season.csv'`: A CSV file with detailed player performance data for the 2024-2025 season, including gameweek-by-gameweek stats for each player (e.g., points, goals, assists, and team results).\n",
    "\n",
    "`'fpl_elements.csv'`: A CSV file with player-level data, including player IDs, names, teams, positions, total points, and selected percentages (this CSV file was created in the previous step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv files\n",
    "\n",
    "# Save each DataFrame to CSV for further analysis\n",
    "\n",
    "element_types_df.to_csv(\"../Official FPL API Files/fpl_element_types.csv\", index=False)\n",
    "teams_df.to_csv(\"../Official FPL API Files/fpl_teams.csv\", index=False)\n",
    "events_df.to_csv(\"../Official FPL API Files/fpl_events.csv\", index=False)\n",
    "game_settings_df.to_csv(\"../Official FPL API Files/fpl_game_settings.csv\", index=False)\n",
    "phases_df.to_csv(\"../Official FPL API Files/fpl_phases.csv\", index=False)\n",
    "gameweek_df.to_csv(\"../Official FPL API Files/FPL API 2024-2025 Season.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data from the Understat API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fetch player data from the Understat API to compile gameweek-level match statistics. An asynchronous HTTP session is created to enable interaction with the Understat API. Player-level data, like ID and aggregate stats, is retrieved for a specified season. The code loops through the list of players retrieved for the season and prints out a sample match structure for the first player in the list for 2020. \n",
    "\n",
    "The goal here is to learn the type of data available through the Understat API, in order to determine which elemnents should be extracted and added to our analysis to supplement the bulk of the data we will use, which will come from the `Vaastav` repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample match data for Harry Kane in 2020: {'goals': '3', 'shots': '6', 'xG': '2.4590251445770264', 'time': '90', 'position': 'FW', 'h_team': 'Bayern Munich', 'a_team': 'Augsburg', 'h_goals': '3', 'a_goals': '0', 'date': '2024-11-22', 'id': '27834', 'season': '2024', 'roster_id': '687931', 'xA': '0', 'assists': '0', 'key_passes': '0', 'npg': '1', 'npxG': '0.9434716701507568', 'xGChain': '1.0221545696258545', 'xGBuildup': '0.07868286967277527'}\n"
     ]
    }
   ],
   "source": [
    "async def fetch_understat_data(season):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        understat = Understat(session)\n",
    "        \n",
    "        # Fetch player data for the specified season in the Premier League\n",
    "        players_data = await understat.get_league_players(\"epl\", season)\n",
    "        \n",
    "        # Create an empty list to hold the player gameweek data\n",
    "        player_gameweek_data = []\n",
    "\n",
    "        for player in players_data:\n",
    "            player_id = player['id']\n",
    "            player_name = player['player_name']\n",
    "            \n",
    "            # Fetch player matches (gameweek data) for each player in the season\n",
    "            matches = await understat.get_player_matches(player_id)\n",
    "            \n",
    "            # Check the structure of a single match\n",
    "            if matches:\n",
    "                print(f\"Sample match data for {player_name} in {season}:\", matches[0])\n",
    "                break\n",
    "\n",
    "# Run this code to view the structure of a match data item\n",
    "await fetch_understat_data(\"2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Understat provides us with expected goals and expected assists, which are two metrics that are missing from the `Vaastav` files prior to the 2022-2023 season. We will want to extract these for our analysis.\n",
    "\n",
    "Now, we will collect these advanced football statistics from the Understat API for multiple Premier League seasons. We will asynchronously retrieve player-level data and match-level statistics, including expected goals (xG), expected assists (xA), and their combined metric, expected goal involvements (xGI), for each player in each gameweek. The collected data is organized into a DataFrame and saved as CSV files, one for each season. The script uses asynchronous processing for efficiency and includes error handling and delays to avoid overloading the server.\n",
    "\n",
    "`NOTE`: This will take 15-20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for the 2016/17 season...\n",
      "Data for 2016/17 saved successfully.\n",
      "Fetching data for the 2017/18 season...\n",
      "Data for 2017/18 saved successfully.\n",
      "Fetching data for the 2018/19 season...\n",
      "Data for 2018/19 saved successfully.\n",
      "Fetching data for the 2019/20 season...\n",
      "Data for 2019/20 saved successfully.\n",
      "Fetching data for the 2020/21 season...\n",
      "Data for 2020/21 saved successfully.\n",
      "Fetching data for the 2021/22 season...\n",
      "Data for 2021/22 saved successfully.\n"
     ]
    }
   ],
   "source": [
    "async def fetch_understat_data(season):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        understat = Understat(session)\n",
    "        \n",
    "        # Fetch player data for the specified season in the Premier League\n",
    "        players_data = await understat.get_league_players(\"epl\", season)\n",
    "        \n",
    "        # Create an empty list to hold the player gameweek data\n",
    "        player_gameweek_data = []\n",
    "\n",
    "        for player in players_data:\n",
    "            player_id = player['id']\n",
    "            player_name = player['player_name']\n",
    "            \n",
    "            # Fetch player matches (gameweek data) for each player in the season\n",
    "            matches = await understat.get_player_matches(player_id)\n",
    "            \n",
    "            # Extract xG, xA, and calculate expected goal involvements\n",
    "            for match in matches:\n",
    "                if match['season'] == season:\n",
    "                    gameweek_data = {\n",
    "                        \"player_name\": player_name,\n",
    "                        \"date\": match['date'],\n",
    "                        \"xG\": float(match['xG']),\n",
    "                        \"xA\": float(match['xA']),\n",
    "                        \"expected_goal_involvements\": float(match['xG']) + float(match['xA'])\n",
    "                    }\n",
    "                    player_gameweek_data.append(gameweek_data)\n",
    "        \n",
    "        # Convert the list to a DataFrame for easy manipulation\n",
    "        return pd.DataFrame(player_gameweek_data)\n",
    "\n",
    "# Fetch data for the seasons from 2016/17 to 2021/22\n",
    "async def main():\n",
    "    seasons = [\"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"]\n",
    "    for season in seasons:\n",
    "        print(f\"Fetching data for the {season}/{str(int(season) + 1)[-2:]} season...\")\n",
    "        try:\n",
    "            season_data = await fetch_understat_data(season)\n",
    "            season_data.to_csv(f\"../Understat API Files/understat_{season}_{str(int(season) + 1)[-2:]}.csv\", index=False)\n",
    "            print(f\"Data for {season}/{str(int(season) + 1)[-2:]} saved successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data for {season}/{str(int(season) + 1)[-2:]}. Error: {e}\")\n",
    "        \n",
    "        # Wait a few seconds between each season request to avoid overloading the server\n",
    "        await asyncio.sleep(5)  # Adjust this delay as needed\n",
    "\n",
    "# Run the asynchronous main function\n",
    "await main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Understat API and Vaastav Data\n",
    "\n",
    "We will now combine Understat data (xG, xA, xGI) with Vaastav's merged_gw files to create a comprehensive dataset for each Premier League season. Player names are normalized in both datasets by removing special characters and suffixes for consistency. Gameweeks are assigned to Understat data based on match dates, grouping matches into 7-day periods, ensuring alignment with gameweek structures in the Vaastav dataset. The datasets are then merged by player name and gameweek, with Understat's metrics (xG, xA, xGI) being matched to the most chronologically-appropriate Vaastav entries. Any unmatched rows in the merged dataset (e.g., where Understat lacks data for a player or gameweek) result in NaN values. The combined data is saved as a CSV for each season, allowing for seamless integration of advanced analytics with official FPL data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined data for 2016-2017 season to ../Combined Files/2016-2017 season data.csv\n",
      "Season 2016-2017: NaN counts - xA: 15178, xG: 15178, xGI: 15178\n",
      "Saved combined data for 2017-2018 season to ../Combined Files/2017-2018 season data.csv\n",
      "Season 2017-2018: NaN counts - xA: 13966, xG: 13966, xGI: 13966\n",
      "Saved combined data for 2018-2019 season to ../Combined Files/2018-2019 season data.csv\n",
      "Season 2018-2019: NaN counts - xA: 13814, xG: 13814, xGI: 13814\n",
      "Saved combined data for 2019-2020 season to ../Combined Files/2019-2020 season data.csv\n",
      "Season 2019-2020: NaN counts - xA: 13562, xG: 13562, xGI: 13562\n",
      "Saved combined data for 2020-2021 season to ../Combined Files/2020-2021 season data.csv\n",
      "Season 2020-2021: NaN counts - xA: 15749, xG: 15749, xGI: 15749\n",
      "Saved combined data for 2021-2022 season to ../Combined Files/2021-2022 season data.csv\n",
      "Season 2021-2022: NaN counts - xA: 16899, xG: 16899, xGI: 16899\n"
     ]
    }
   ],
   "source": [
    "def normalize_name(name):\n",
    "    \"\"\"Normalize player names by removing special characters and suffixes.\"\"\"\n",
    "    name = unicodedata.normalize('NFKD', name)\n",
    "    name = ''.join(c for c in name if not unicodedata.combining(c))\n",
    "    if \"_\" in name:\n",
    "        # Remove suffix numbers, e.g., '_191'\n",
    "        name = '_'.join(name.split('_')[:2])\n",
    "    return name.replace(\"_\", \" \")  # Replace underscores with spaces\n",
    "\n",
    "def assign_gameweeks(understat_df):\n",
    "    \"\"\"Assign gameweeks based on the date column in the understat data.\"\"\"\n",
    "    # Sort dates chronologically\n",
    "    understat_df['date'] = pd.to_datetime(understat_df['date'])\n",
    "    understat_df = understat_df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "    # Initialize gameweek assignment\n",
    "    gameweeks = []\n",
    "    current_gw_start = understat_df['date'].iloc[0]\n",
    "    current_gw_end = current_gw_start + timedelta(days=6)\n",
    "    current_gw = 1\n",
    "\n",
    "    for game_date in understat_df['date']:\n",
    "        if game_date > current_gw_end:\n",
    "            # Start a new gameweek\n",
    "            current_gw_start = game_date\n",
    "            current_gw_end = current_gw_start + timedelta(days=6)\n",
    "            current_gw += 1\n",
    "        gameweeks.append(current_gw)\n",
    "\n",
    "    understat_df['gameweek'] = gameweeks\n",
    "    return understat_df\n",
    "\n",
    "def merge_understat_with_merged_gw(season_start, season_end):\n",
    "    \"\"\"Merge understat data with merged_gw data for a given season.\"\"\"\n",
    "    understat_file = f\"../Understat API Files/understat_20{season_start}_{season_end}.csv\"\n",
    "    merged_gw_file = f\"../Vaastav Repository Files (CSV Downloads)/merged_gw_{season_start[-2:]}{season_end[-2:]}.csv\"\n",
    "    output_file = f\"../Combined Files/20{season_start}-20{season_end} season data.csv\"\n",
    "\n",
    "    # Load the data with proper encoding\n",
    "    understat_df = pd.read_csv(understat_file, encoding='ISO-8859-1')\n",
    "    merged_gw_df = pd.read_csv(merged_gw_file, encoding='ISO-8859-1')\n",
    "\n",
    "    # Normalize names in both datasets\n",
    "    merged_gw_df['name'] = merged_gw_df['name'].apply(normalize_name)\n",
    "    understat_df['player_name'] = understat_df['player_name'].apply(normalize_name)\n",
    "\n",
    "    # Assign gameweeks based on understat dates\n",
    "    understat_df = assign_gameweeks(understat_df)\n",
    "\n",
    "    # Convert kickoff_time to date format (YYYY-MM-DD)\n",
    "    merged_gw_df['kickoff_date'] = pd.to_datetime(merged_gw_df['kickoff_time']).dt.date\n",
    "    understat_df['date'] = understat_df['date'].dt.date\n",
    "\n",
    "    # Merge data on name and gameweek\n",
    "    combined_df = pd.merge(\n",
    "        merged_gw_df,\n",
    "        understat_df,\n",
    "        left_on=['name', 'kickoff_date'],\n",
    "        right_on=['player_name', 'date'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Drop redundant columns\n",
    "    combined_df.drop(['player_name', 'date', 'kickoff_date'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the combined data\n",
    "    combined_df.to_csv(output_file, index=False, na_rep='NaN')\n",
    "    print(f\"Saved combined data for 20{season_start}-20{season_end} season to {output_file}\")\n",
    "\n",
    "    # Report the number of NaN rows in xA, xG, and xGI columns\n",
    "    nan_counts = combined_df[['xA', 'xG', 'expected_goal_involvements']].isna().sum()\n",
    "    print(f\"Season 20{season_start}-20{season_end}: NaN counts - xA: {nan_counts['xA']}, xG: {nan_counts['xG']}, xGI: {nan_counts['expected_goal_involvements']}\")\n",
    "\n",
    "\n",
    "# List of seasons\n",
    "seasons = [\n",
    "    (\"16\", \"17\"),\n",
    "    (\"17\", \"18\"),\n",
    "    (\"18\", \"19\"),\n",
    "    (\"19\", \"20\"),\n",
    "    (\"20\", \"21\"),\n",
    "    (\"21\", \"22\"),\n",
    "]\n",
    "\n",
    "# Process each season\n",
    "for season_start, season_end in seasons:\n",
    "    merge_understat_with_merged_gw(season_start, season_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we merged the Understat and Vaastav data only through the 2021-2022 season. We do this because later seasons (22/23, 23/24, and the ongoing 24/25) already include advanced metrics (xG, xA, xGI) in the Vaastav and official FPL API data, so the existing files can already be considered 'combined' and do not need further alterations.\n",
    "\n",
    "Below, we will copy and rename these final 3 files into the same directory as the files we just combined using both Vaastav and Understat data (D.R.E.A.M./Combined Files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied and renamed: ../Vaastav Repository Files (CSV Downloads)/merged_gw_2223.csv -> ../Combined Files/2022-2023 season data.csv\n",
      "Copied and renamed: ../Vaastav Repository Files (CSV Downloads)/merged_gw_2324.csv -> ../Combined Files/2023-2024 season data.csv\n",
      "Copied and renamed: ../Vaastav Repository Files (CSV Downloads)/merged_gw_2425.csv -> ../Combined Files/2024-2025 season data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define source and destination directories\n",
    "source_dir = \"../Vaastav Repository Files (CSV Downloads)\"\n",
    "destination_dir = \"../Combined Files\"\n",
    "\n",
    "# List of source and destination file names\n",
    "files_to_copy = [\n",
    "    (\"merged_gw_2223.csv\", \"2022-2023 season data.csv\"),\n",
    "    (\"merged_gw_2324.csv\", \"2023-2024 season data.csv\"),\n",
    "    (\"merged_gw_2425.csv\", \"2024-2025 season data.csv\"),\n",
    "]\n",
    "\n",
    "# Iterate through the list and copy/rename files\n",
    "for source_file, destination_file in files_to_copy:\n",
    "    source_path = os.path.join(source_dir, source_file)\n",
    "    destination_path = os.path.join(destination_dir, destination_file)\n",
    "\n",
    "    try:\n",
    "        shutil.copy(source_path, destination_path)\n",
    "        print(f\"Copied and renamed: {source_path} -> {destination_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {source_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {source_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting into DataFrames and Creating a Master File\n",
    "\n",
    "First, we will create a dataframe for each combined file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1617 = pd.read_csv('../Combined Files/2016-2017 season data.csv')\n",
    "s1718 = pd.read_csv('../Combined Files/2017-2018 season data.csv')\n",
    "s1819 = pd.read_csv('../Combined Files/2018-2019 season data.csv')\n",
    "s1920 = pd.read_csv('../Combined Files/2019-2020 season data.csv')\n",
    "s2021 = pd.read_csv('../Combined Files/2020-2021 season data.csv')\n",
    "s2122 = pd.read_csv('../Combined Files/2021-2022 season data.csv')\n",
    "s2223 = pd.read_csv('../Combined Files/2022-2023 season data.csv')\n",
    "s2324 = pd.read_csv('../Combined Files/2023-2024 season data.csv')\n",
    "s2425 = pd.read_csv('../Combined Files/2024-2025 season data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a list of the dataframes and iterate through them to align certain columns that may be referred to differently across the Understat and Vaastav files. xA will be called expected_assists, xG will be called expected_goals, ict_index will be called Influence_Creativity_Threat_Index, and the gameweek column will be dropped (because this data can be extracted from the datetime column 'kickoff time') across all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_list = [s1617, s1718, s1819, s1920, s2021, s2122, s2223, s2324, s2425]\n",
    "\n",
    "for df in season_list:\n",
    "    if 'xA' in df.columns:\n",
    "        df.rename(columns={'xA': 'expected_assists'}, inplace=True)\n",
    "    if 'xG' in df.columns:\n",
    "        df.rename(columns={'xG': 'expected_goals'}, inplace=True)\n",
    "    if 'ict_index' in df.columns:\n",
    "        df.rename(columns={'ict_index': 'Influence_Creativity_Threat_Index'}, inplace=True)\n",
    "    if 'gameweek' in df.columns:\n",
    "        df.drop(columns=['gameweek'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to examine the columns that are shared across the dataframes vs the ones unique to certain seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared columns across all DataFrames:\n",
      "{'influence', 'opponent_team', 'goals_conceded', 'yellow_cards', 'own_goals', 'was_home', 'value', 'Influence_Creativity_Threat_Index', 'saves', 'transfers_balance', 'kickoff_time', 'clean_sheets', 'total_points', 'red_cards', 'round', 'bonus', 'element', 'minutes', 'goals_scored', 'team_a_score', 'penalties_missed', 'expected_assists', 'GW', 'bps', 'threat', 'creativity', 'selected', 'transfers_in', 'penalties_saved', 'expected_goal_involvements', 'name', 'transfers_out', 'assists', 'team_h_score', 'expected_goals', 'fixture'}\n",
      "\n",
      "\n",
      "Season: Season 16-17\n",
      "Unique columns: {'dribbles', 'target_missed', 'big_chances_missed', 'offside', 'clearances_blocks_interceptions', 'kickoff_time_formatted', 'id', 'loaned_out', 'tackled', 'loaned_in', 'ea_index', 'tackles', 'fouls', 'completed_passes', 'errors_leading_to_goal', 'penalties_conceded', 'key_passes', 'recoveries', 'big_chances_created', 'open_play_crosses', 'winning_goals', 'attempted_passes', 'errors_leading_to_goal_attempt'}\n",
      "\n",
      "\n",
      "Season: Season 17-18\n",
      "Unique columns: {'dribbles', 'target_missed', 'big_chances_missed', 'offside', 'clearances_blocks_interceptions', 'kickoff_time_formatted', 'id', 'loaned_out', 'tackled', 'loaned_in', 'ea_index', 'tackles', 'fouls', 'completed_passes', 'errors_leading_to_goal', 'penalties_conceded', 'key_passes', 'recoveries', 'big_chances_created', 'open_play_crosses', 'winning_goals', 'attempted_passes', 'errors_leading_to_goal_attempt'}\n",
      "\n",
      "\n",
      "Season: Season 18-19\n",
      "Unique columns: {'dribbles', 'target_missed', 'big_chances_missed', 'offside', 'clearances_blocks_interceptions', 'kickoff_time_formatted', 'id', 'loaned_out', 'tackled', 'loaned_in', 'ea_index', 'tackles', 'fouls', 'completed_passes', 'errors_leading_to_goal', 'penalties_conceded', 'key_passes', 'recoveries', 'big_chances_created', 'open_play_crosses', 'winning_goals', 'attempted_passes', 'errors_leading_to_goal_attempt'}\n",
      "\n",
      "\n",
      "Season: Season 19-20\n",
      "Unique columns: None\n",
      "\n",
      "\n",
      "Season: Season 20-21\n",
      "Unique columns: {'position', 'team', 'xP'}\n",
      "\n",
      "\n",
      "Season: Season 21-22\n",
      "Unique columns: {'position', 'team', 'xP'}\n",
      "\n",
      "\n",
      "Season: Season 22-23\n",
      "Unique columns: {'starts', 'xP', 'expected_goals_conceded', 'position', 'team'}\n",
      "\n",
      "\n",
      "Season: Season 23-24\n",
      "Unique columns: {'starts', 'xP', 'expected_goals_conceded', 'position', 'team'}\n",
      "\n",
      "\n",
      "Season: Season 24-25\n",
      "Unique columns: {'starts', 'xP', 'expected_goals_conceded', 'position', 'team'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store column names for each DataFrame\n",
    "df_columns = {}\n",
    "\n",
    "# Extract column names for each DataFrame\n",
    "for i, df in enumerate(season_list):\n",
    "    try:\n",
    "        season_name = f\"Season {16 + i}-{17 + i}\"  # Create a season label\n",
    "        df_columns[season_name] = set(df.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {season_name}: {e}\")\n",
    "\n",
    "# Find columns shared by all DataFrames (intersection of all column sets)\n",
    "shared_columns = set.intersection(*df_columns.values())\n",
    "\n",
    "# Print shared columns\n",
    "print(\"Shared columns across all DataFrames:\")\n",
    "print(shared_columns)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Identify and print unique columns for each DataFrame\n",
    "for season, columns in df_columns.items():\n",
    "    unique_columns = columns - shared_columns\n",
    "    print(f\"Season: {season}\")\n",
    "    print(f\"Unique columns: {unique_columns if unique_columns else 'None'}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important observations:\n",
    "\n",
    "1) We notice that all dataframes share several columns common across all seasons, especially fundamental data like player name, fixture, home vs away information, and basic appearance and scoring metrics. \n",
    "2) 2019/2020 season has the smallest number of columns, mainly due to the initial impact of the COVID-19 pandemic and the distortion in the PL schedule.\n",
    "3) 2016/2017, 2017/2018, and 2018/2019 are aligned in terms of columns shared, while 2020/2021 to 2024/2025 are also aligned.\n",
    "\n",
    "To ensure complete consistency in the 2020/2021 to 2024/2025 seasons, we will drop the `'expected_goals_conceded'` and `'starts'` columns, which are absent from seasons 2020/2021 and 2021/2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [s2223, s2324, s2425]:\n",
    "    df.drop(columns=['expected_goals_conceded', 'starts'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check again to see what columns are shared by seasons 2020/2021 to 2024/2025. They should have all columns in common now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared columns across all DataFrames:\n",
      "{'influence', 'opponent_team', 'goals_conceded', 'yellow_cards', 'own_goals', 'was_home', 'value', 'Influence_Creativity_Threat_Index', 'saves', 'transfers_balance', 'kickoff_time', 'team', 'clean_sheets', 'total_points', 'red_cards', 'round', 'position', 'bonus', 'element', 'expected_assists', 'goals_scored', 'minutes', 'penalties_missed', 'team_a_score', 'GW', 'bps', 'threat', 'creativity', 'selected', 'transfers_in', 'penalties_saved', 'expected_goal_involvements', 'name', 'transfers_out', 'assists', 'team_h_score', 'expected_goals', 'fixture', 'xP'}\n",
      "\n",
      "\n",
      "Season: Season 20-21\n",
      "Unique columns: None\n",
      "\n",
      "\n",
      "Season: Season 21-22\n",
      "Unique columns: None\n",
      "\n",
      "\n",
      "Season: Season 22-23\n",
      "Unique columns: None\n",
      "\n",
      "\n",
      "Season: Season 23-24\n",
      "Unique columns: None\n",
      "\n",
      "\n",
      "Season: Season 24-25\n",
      "Unique columns: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store column names for each DataFrame\n",
    "df_columns = {}\n",
    "list2 = [s2021, s2122, s2223, s2324, s2425]\n",
    "\n",
    "# Extract column names for each DataFrame\n",
    "for i, df in enumerate(list2):\n",
    "    try:\n",
    "        season_name = f\"Season {20 + i}-{21 + i}\"  # Create a season label\n",
    "        df_columns[season_name] = set(df.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {season_name}: {e}\")\n",
    "\n",
    "# Find columns shared by all DataFrames (intersection of all column sets)\n",
    "shared_columns = set.intersection(*df_columns.values())\n",
    "\n",
    "# Print shared columns\n",
    "print(\"Shared columns across all DataFrames:\")\n",
    "print(shared_columns)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Identify and print unique columns for each DataFrame\n",
    "for season, columns in df_columns.items():\n",
    "    unique_columns = columns - shared_columns\n",
    "    print(f\"Season: {season}\")\n",
    "    print(f\"Unique columns: {unique_columns if unique_columns else 'None'}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now combine the individual seasonal dataframes into a `'master'` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>team</th>\n",
       "      <th>xP</th>\n",
       "      <th>assists</th>\n",
       "      <th>bonus</th>\n",
       "      <th>bps</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>creativity</th>\n",
       "      <th>element</th>\n",
       "      <th>...</th>\n",
       "      <th>transfers_balance</th>\n",
       "      <th>transfers_in</th>\n",
       "      <th>transfers_out</th>\n",
       "      <th>value</th>\n",
       "      <th>was_home</th>\n",
       "      <th>yellow_cards</th>\n",
       "      <th>GW</th>\n",
       "      <th>expected_goals</th>\n",
       "      <th>expected_assists</th>\n",
       "      <th>expected_goal_involvements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Connolly</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>DEF</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>435</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Mooy</td>\n",
       "      <td>MID</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Ramsdale</td>\n",
       "      <td>GK</td>\n",
       "      <td>Sheffield Utd</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdoulaye DoucourA©</td>\n",
       "      <td>MID</td>\n",
       "      <td>Everton</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>44.6</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205708</td>\n",
       "      <td>0.205708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name position           team   xP  assists  bonus  bps  \\\n",
       "0       Aaron Connolly      FWD       Brighton  0.5        0      0   -3   \n",
       "1      Aaron Cresswell      DEF       West Ham  2.1        0      0   11   \n",
       "2           Aaron Mooy      MID       Brighton  0.0        0      0    0   \n",
       "3       Aaron Ramsdale       GK  Sheffield Utd  2.5        0      0   12   \n",
       "4  Abdoulaye DoucourA©      MID        Everton  1.3        0      0   20   \n",
       "\n",
       "   clean_sheets  creativity  element  ...  transfers_balance  transfers_in  \\\n",
       "0             0         0.3       78  ...                  0             0   \n",
       "1             0        11.2      435  ...                  0             0   \n",
       "2             0         0.0       60  ...                  0             0   \n",
       "3             0         0.0      483  ...                  0             0   \n",
       "4             1        44.6      512  ...                  0             0   \n",
       "\n",
       "   transfers_out  value  was_home yellow_cards  GW  expected_goals  \\\n",
       "0              0     55      True            0   1        0.392763   \n",
       "1              0     50      True            0   1        0.000000   \n",
       "2              0     50      True            0   1             NaN   \n",
       "3              0     50      True            0   1        0.000000   \n",
       "4              0     55     False            0   1        0.000000   \n",
       "\n",
       "   expected_assists  expected_goal_involvements  \n",
       "0          0.000000                    0.392763  \n",
       "1          0.000000                    0.000000  \n",
       "2               NaN                         NaN  \n",
       "3          0.000000                    0.000000  \n",
       "4          0.205708                    0.205708  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all DataFrames into a single DataFrame\n",
    "master = pd.concat(list2, ignore_index=True)\n",
    "\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how large the dataframe is and how many missing values it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of master dataframe:  (111920, 39)\n",
      "Number of missing values in master dataframe:  32648\n"
     ]
    }
   ],
   "source": [
    "print('Shape of master dataframe: ', master.shape)\n",
    "print('Number of missing values in master dataframe: ', master.isna().any(axis=1).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to save this master dataframe into a `'master.csv'` file, on which we will perform EDA, visualizations, and eventually train an ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a CSV file\n",
    "master.to_csv(\"../master.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for seasons 2016/2017 to 2018/2019. We will ignore season 2019/2020 due to its relative dearth of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>assists</th>\n",
       "      <th>attempted_passes</th>\n",
       "      <th>big_chances_created</th>\n",
       "      <th>big_chances_missed</th>\n",
       "      <th>bonus</th>\n",
       "      <th>bps</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>clearances_blocks_interceptions</th>\n",
       "      <th>completed_passes</th>\n",
       "      <th>...</th>\n",
       "      <th>transfers_in</th>\n",
       "      <th>transfers_out</th>\n",
       "      <th>value</th>\n",
       "      <th>was_home</th>\n",
       "      <th>winning_goals</th>\n",
       "      <th>yellow_cards</th>\n",
       "      <th>GW</th>\n",
       "      <th>expected_goals</th>\n",
       "      <th>expected_assists</th>\n",
       "      <th>expected_goal_involvements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Lennon</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Ramsey</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abdoulaye Doucoure</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdul Rahman Baba</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  assists  attempted_passes  big_chances_created  \\\n",
       "0     Aaron Cresswell        0                 0                    0   \n",
       "1        Aaron Lennon        0                 3                    0   \n",
       "2        Aaron Ramsey        0                26                    0   \n",
       "3  Abdoulaye Doucoure        0                 0                    0   \n",
       "4   Abdul Rahman Baba        0                 0                    0   \n",
       "\n",
       "   big_chances_missed  bonus  bps  clean_sheets  \\\n",
       "0                   0      0    0             0   \n",
       "1                   0      0    6             0   \n",
       "2                   0      0    5             0   \n",
       "3                   0      0    0             0   \n",
       "4                   0      0    0             0   \n",
       "\n",
       "   clearances_blocks_interceptions  completed_passes  ...  transfers_in  \\\n",
       "0                                0                 0  ...             0   \n",
       "1                                1                 2  ...             0   \n",
       "2                                2                22  ...             0   \n",
       "3                                0                 0  ...             0   \n",
       "4                                0                 0  ...             0   \n",
       "\n",
       "   transfers_out  value  was_home  winning_goals  yellow_cards  GW  \\\n",
       "0              0     55     False              0             0   1   \n",
       "1              0     60      True              0             0   1   \n",
       "2              0     80      True              0             0   1   \n",
       "3              0     50     False              0             0   1   \n",
       "4              0     55      True              0             0   1   \n",
       "\n",
       "   expected_goals  expected_assists  expected_goal_involvements  \n",
       "0             NaN               NaN                         NaN  \n",
       "1        0.000000               0.0                    0.000000  \n",
       "2        0.076822               0.0                    0.076822  \n",
       "3             NaN               NaN                         NaN  \n",
       "4             NaN               NaN                         NaN  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of DataFrames to combine\n",
    "dataframes_old = [s1617, s1718, s1819]\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "df_old = pd.concat(dataframes_old, ignore_index=True)\n",
    "\n",
    "df_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of old dataframe:  (67936, 59)\n",
      "Number of missing values in old dataframe:  42958\n"
     ]
    }
   ],
   "source": [
    "print('Shape of old dataframe: ', df_old.shape)\n",
    "print('Number of missing values in old dataframe: ', df_old.isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many missing values in the older seasons (42958 NaNs out of 67936 rows). Therefore, we will focus our EDA, visuals, and model training on the `'master'` file: Premier League seasons 2020/2021 to 2024/2025."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
