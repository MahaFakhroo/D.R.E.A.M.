# Data Rules Everything Around Me (DREAM) Team
# Fantasy Premier League (FPL) - Player Performance Analysis


## Project Description:
This project aims to analyze Fantasy Premier League (FPL) data to uncover player and team performance insights. By leveraging data from sources like Vaastav's GitHub repository, the official FPL API, and the Understat API, the project involves cleaning, exploring, and modeling data to predict FPL points and visualize trends. The repository includes scripts for data wrangling, exploratory data analysis/visualization, and machine learning, providing comprehensive, data-driven insights to help FPL managers in their strategic decision-making. 

This repository:
1) Extracts and combines raw data from multiple sources.
2) Cleans and processes the raw data into analysis-ready format.
3) Creates visualizations and trends to analyze FPL player performance.
4) Creates a random forest ML model to predict player points based on available features.


## Teammates:
1. Feras Abdulla
2. Syed Shahid Hossaini
3. Maha Fakhroo
4. Eric Guan


## Work Distribution and Attribution:
1. `Feras Abdulla`: Data Wrangling, Data Cleaning, Data Visualization, ML Model, Medium Article
2. `Syed Shahid Hossaini`: Literature Review, Exploratory Data Analysis, Data Visualization, Analysis and Interpretation
3. `Maha Fakhroo`: Exploratory Data Analysis, Data Visualization, Analysis and Interpretation, PPT Presentation
4. `Eric Guan`: Exploratory Data Analysis, Data Visualization, Medium Article


## Link to Github Repository (to clone the repository locally)
https://github.com/MahaFakhroo/D.R.E.A.M.


## Data Sources:
1. **Vaastav's GitHub Repository**:  
   Format: Downloadable CSV Files
   Anand, V. (2022). *FPL Historical Dataset*. GitHub. Retrieved November 2024 from [https://github.com/vaastav/Fantasy-Premier-League]

2. **Official Fantasy Premier League API**:  
   Format: API/JSON
   Premier League. (2024). *Fantasy Premier League API*. Retrieved November 2024 from [https://fantasy.premierleague.com]

3. **Understat API**:  
   Format: API/JSON
   Understat. (2024). *Understat API for xG and xA Data*. Retrieved November 2024 from [https://understat.com]


## Usage of Python Files:
**NOTE:** The Python files should be run from their current location in the repository: `D.R.E.A.M./Python Scripts`. Care was taken to ensure that all files used in the code have the correct, current paths.

1. `'Data_Wrangling.ipynb'`:
This is the first file users should access and run. It extracts data from the Official Fantasy Premier League API and the Understat API and saves this data to CSV and/or Pandas DataFrame formats. It then merges extracted data from these API endpoints containing advanced metrics (like expected goals xG, expected assists xA, and expected goal involvement xGI) with the downloaded CSV files from the Vaastav Github Repository. It does this through a custom counter function that aligns gameweek or fixture data between the two sets of data sources temporally. It also aligns common features by renaming shared columns in a structured convention. It then drops extraneous columns, concatenates the dataframes, and generates a master DataFrame and CSV file: `'master.csv`'.

2. `'EDA_Visuals.ipynb'`:
This is the second file users should access and run. It uploads the `'master.csv'` file generated by `'Data_Wrangling.ipynb'` into a DataFrame. Exploratory data analysis is conducted on the data to understand its content, its validity, and its boundaries. The data is then cleaned systematically, with categorical columns aligned and encoded, missing and invalid data imputed or dropped, unit and naming issues addressed, and cumulative and/or combined features created. The data is then saved as a cleaned CSV file: `'master_cleaned.csv'`. This cleaned CSV file is loaded into a DataFrame and then visualizations are created to analyze FPL player performance and create a storytelling flow, which is the purpose of our project.

3. `'ML_Points_Predictor'`:
This is the last file users should access and run. As stated in the project proposal, the main focus of our project is to analyze player performance through exploratory data analysis and visualizations. An ML model would only be created resource- and time-permitting. This file creates a preliminary random forest model based on the data in `'master_cleaned.csv'`. Feature engineering is executed on the data set, and the model is trained and cross-validated. Further, predictions are made on two splits of the data: one random, and one based on season (trained on 2020-2024, tested on 2024-2025). Feature importances are listed, and model performance is evaluated by plotting residuals and calculating the R2, MAE, MSE metrics.


## Folder Hierarchy:
`'Vaastav Repository Files (CSV Downloads)'`: Contains the CSV files downloaded from the Vaastav Github repository. These files form the bulk of our data, and contain detailed fixture and player statistics structured gameweek by gameweek, from the 2016-2017 season to the 2024-2025 season.

`'Official FPL API Files'`: Contains CSV files generated by converting Pandas DataFrames into CSV format. The data is collected by accessing the Official FPL API endpoint (see Data_Wrangling.ipynb). This data is specific to the current, ongoing Premier League season (2024-2025).

`'Understat API Files'`: Contains CSV files generated by converting Pandas DataFrames into CSV format. The data (xG, xA, xGI) is collected by accessing the Understat API endpoint (see Data_Wrangling.ipynb), from the 2016-2017 season to the 2021-2022 season. Advanced metrics were not collected for seasons 22/23, 23/24, and 24/25 because xG, xA, and xGI are already available for later seasons in the Vaastav data set.

`'Combined Files'`: Contains CSV files generated by combining the data downloaded from the Vaastav Github repository and the data extracted from the API endpoints (see Data_Wrangling.ipynb). These files serve as the component pieces to be concatenated into our master file, `'master.csv'`. 

`'Python Scripts'`: This folder contains our three .ipynb files, as explained in the `Usage of Python Files` section above. They also contain .html versions of those three files.

`'master.csv'`: the ultimate concatenation of our data across multiple seasons, used as a foundation for data cleaning (see Data_Wrangling.ipynb).

`'master_cleaned.csv'`: the cleaned version of our master file, used as a foundation for EDA, visualizations, and training our ML model (see EDA_Visuals.ipynb). 


## Contact:
For questions or further information about the Github repository, please contact:
Feras Abdulla (feras.abdulla@mail.utoronto.ca)